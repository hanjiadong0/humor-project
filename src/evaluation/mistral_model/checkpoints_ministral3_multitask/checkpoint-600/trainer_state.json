{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3333333333333333,
  "eval_steps": 200,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005555555555555556,
      "grad_norm": 158.9470672607422,
      "learning_rate": 1.323529411764706e-05,
      "loss": 9.272794342041015,
      "step": 10
    },
    {
      "epoch": 0.011111111111111112,
      "grad_norm": 100.57749938964844,
      "learning_rate": 2.7941176470588236e-05,
      "loss": 5.063174438476563,
      "step": 20
    },
    {
      "epoch": 0.016666666666666666,
      "grad_norm": 61.725582122802734,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 4.662820434570312,
      "step": 30
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 100.87826538085938,
      "learning_rate": 5.735294117647059e-05,
      "loss": 4.701358032226563,
      "step": 40
    },
    {
      "epoch": 0.027777777777777776,
      "grad_norm": 168.10183715820312,
      "learning_rate": 7.205882352941177e-05,
      "loss": 5.1286170959472654,
      "step": 50
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 190.6706085205078,
      "learning_rate": 8.676470588235295e-05,
      "loss": 2.1992259979248048,
      "step": 60
    },
    {
      "epoch": 0.03888888888888889,
      "grad_norm": 173.79345703125,
      "learning_rate": 0.00010147058823529412,
      "loss": 2.614208793640137,
      "step": 70
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 58.71852493286133,
      "learning_rate": 0.00011617647058823531,
      "loss": 4.229814910888672,
      "step": 80
    },
    {
      "epoch": 0.05,
      "grad_norm": 37.42049789428711,
      "learning_rate": 0.00013088235294117647,
      "loss": 3.3103874206542967,
      "step": 90
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 44.01933670043945,
      "learning_rate": 0.00014558823529411765,
      "loss": 2.818774604797363,
      "step": 100
    },
    {
      "epoch": 0.06111111111111111,
      "grad_norm": 203.669677734375,
      "learning_rate": 0.00016029411764705885,
      "loss": 4.24677848815918,
      "step": 110
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 88.42173767089844,
      "learning_rate": 0.000175,
      "loss": 3.9532085418701173,
      "step": 120
    },
    {
      "epoch": 0.07222222222222222,
      "grad_norm": 57.61148452758789,
      "learning_rate": 0.00018970588235294117,
      "loss": 4.358443832397461,
      "step": 130
    },
    {
      "epoch": 0.07777777777777778,
      "grad_norm": 117.97345733642578,
      "learning_rate": 0.00019999983971961317,
      "loss": 4.2059272766113285,
      "step": 140
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 45.78824996948242,
      "learning_rate": 0.00019999699030480704,
      "loss": 1.9864465713500976,
      "step": 150
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 41.7475471496582,
      "learning_rate": 0.00019999057922044582,
      "loss": 3.7269493103027345,
      "step": 160
    },
    {
      "epoch": 0.09444444444444444,
      "grad_norm": 45.564353942871094,
      "learning_rate": 0.000199980606694878,
      "loss": 1.8756668090820312,
      "step": 170
    },
    {
      "epoch": 0.1,
      "grad_norm": 42.002716064453125,
      "learning_rate": 0.00019996707308330263,
      "loss": 1.442580223083496,
      "step": 180
    },
    {
      "epoch": 0.10555555555555556,
      "grad_norm": 19.91563606262207,
      "learning_rate": 0.0001999499788677568,
      "loss": 1.7155799865722656,
      "step": 190
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 25.949182510375977,
      "learning_rate": 0.0001999293246570983,
      "loss": 2.2380443572998048,
      "step": 200
    },
    {
      "epoch": 0.1111111111111111,
      "eval_cls_acc": 0.91625,
      "eval_cls_f1": 0.9127148135663328,
      "eval_loss": 2.150881052017212,
      "eval_reg_mae": 1.1087709975242614,
      "eval_reg_r2": 0.28776373399946953,
      "eval_reg_rmse": 1.394027804026841,
      "eval_runtime": 40.5608,
      "eval_samples_per_second": 19.723,
      "eval_steps_per_second": 2.465,
      "step": 200
    },
    {
      "epoch": 0.11666666666666667,
      "grad_norm": 14.926071166992188,
      "learning_rate": 0.00019990511118698402,
      "loss": 2.626078224182129,
      "step": 210
    },
    {
      "epoch": 0.12222222222222222,
      "grad_norm": 33.26243591308594,
      "learning_rate": 0.00019987733931984365,
      "loss": 1.382942295074463,
      "step": 220
    },
    {
      "epoch": 0.12777777777777777,
      "grad_norm": 20.93137550354004,
      "learning_rate": 0.00019984601004484915,
      "loss": 2.140966033935547,
      "step": 230
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 42.313899993896484,
      "learning_rate": 0.00019981112447787933,
      "loss": 2.118066596984863,
      "step": 240
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 114.96437072753906,
      "learning_rate": 0.00019977268386148022,
      "loss": 2.059064483642578,
      "step": 250
    },
    {
      "epoch": 0.14444444444444443,
      "grad_norm": 6.773175239562988,
      "learning_rate": 0.00019973068956482073,
      "loss": 1.7597187042236329,
      "step": 260
    },
    {
      "epoch": 0.15,
      "grad_norm": 57.23797607421875,
      "learning_rate": 0.00019968514308364398,
      "loss": 1.0722427368164062,
      "step": 270
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 19.37088394165039,
      "learning_rate": 0.00019963604604021398,
      "loss": 1.946426773071289,
      "step": 280
    },
    {
      "epoch": 0.16111111111111112,
      "grad_norm": 49.9411506652832,
      "learning_rate": 0.00019958340018325776,
      "loss": 2.3410356521606444,
      "step": 290
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 23.300642013549805,
      "learning_rate": 0.0001995272073879032,
      "loss": 2.3315874099731446,
      "step": 300
    },
    {
      "epoch": 0.17222222222222222,
      "grad_norm": 35.45706558227539,
      "learning_rate": 0.0001994674696556123,
      "loss": 0.903665828704834,
      "step": 310
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 47.29347229003906,
      "learning_rate": 0.00019940418911410963,
      "loss": 2.016396331787109,
      "step": 320
    },
    {
      "epoch": 0.18333333333333332,
      "grad_norm": 23.324478149414062,
      "learning_rate": 0.00019933736801730687,
      "loss": 3.0907976150512697,
      "step": 330
    },
    {
      "epoch": 0.18888888888888888,
      "grad_norm": 18.881168365478516,
      "learning_rate": 0.00019926700874522228,
      "loss": 2.132109451293945,
      "step": 340
    },
    {
      "epoch": 0.19444444444444445,
      "grad_norm": 56.17744827270508,
      "learning_rate": 0.0001991931138038961,
      "loss": 2.949274253845215,
      "step": 350
    },
    {
      "epoch": 0.2,
      "grad_norm": 23.8775577545166,
      "learning_rate": 0.00019911568582530113,
      "loss": 1.3296625137329101,
      "step": 360
    },
    {
      "epoch": 0.20555555555555555,
      "grad_norm": 11.434427261352539,
      "learning_rate": 0.0001990347275672491,
      "loss": 0.7494820594787598,
      "step": 370
    },
    {
      "epoch": 0.2111111111111111,
      "grad_norm": 36.442745208740234,
      "learning_rate": 0.00019895024191329247,
      "loss": 1.6542146682739258,
      "step": 380
    },
    {
      "epoch": 0.21666666666666667,
      "grad_norm": 56.50474166870117,
      "learning_rate": 0.00019886223187262162,
      "loss": 1.355854606628418,
      "step": 390
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 25.662233352661133,
      "learning_rate": 0.00019877070057995768,
      "loss": 2.8117319107055665,
      "step": 400
    },
    {
      "epoch": 0.2222222222222222,
      "eval_cls_acc": 0.875,
      "eval_cls_f1": 0.8589314053958738,
      "eval_loss": 1.5755611658096313,
      "eval_reg_mae": 0.8487704452872277,
      "eval_reg_r2": 0.5472054325977889,
      "eval_reg_rmse": 1.1115013587135378,
      "eval_runtime": 40.6894,
      "eval_samples_per_second": 19.661,
      "eval_steps_per_second": 2.458,
      "step": 400
    },
    {
      "epoch": 0.22777777777777777,
      "grad_norm": 23.89740562438965,
      "learning_rate": 0.00019867565129544096,
      "loss": 1.1963375091552735,
      "step": 410
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 50.05122756958008,
      "learning_rate": 0.00019857708740451483,
      "loss": 1.5435500144958496,
      "step": 420
    },
    {
      "epoch": 0.2388888888888889,
      "grad_norm": 15.31118392944336,
      "learning_rate": 0.00019847501241780502,
      "loss": 1.3499176025390625,
      "step": 430
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 12.834403038024902,
      "learning_rate": 0.00019836942997099465,
      "loss": 1.370004940032959,
      "step": 440
    },
    {
      "epoch": 0.25,
      "grad_norm": 261.11175537109375,
      "learning_rate": 0.00019826034382469478,
      "loss": 1.7234275817871094,
      "step": 450
    },
    {
      "epoch": 0.25555555555555554,
      "grad_norm": 144.90817260742188,
      "learning_rate": 0.00019814775786431045,
      "loss": 2.6813785552978517,
      "step": 460
    },
    {
      "epoch": 0.2611111111111111,
      "grad_norm": 12.103132247924805,
      "learning_rate": 0.00019803167609990218,
      "loss": 1.8399497985839843,
      "step": 470
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 43.150814056396484,
      "learning_rate": 0.00019791210266604327,
      "loss": 1.1234117507934571,
      "step": 480
    },
    {
      "epoch": 0.2722222222222222,
      "grad_norm": 16.60707664489746,
      "learning_rate": 0.00019778904182167254,
      "loss": 2.790641021728516,
      "step": 490
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 8.037049293518066,
      "learning_rate": 0.00019766249794994246,
      "loss": 0.999112606048584,
      "step": 500
    },
    {
      "epoch": 0.2833333333333333,
      "grad_norm": 60.8162841796875,
      "learning_rate": 0.0001975324755580633,
      "loss": 3.091460037231445,
      "step": 510
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 16.282169342041016,
      "learning_rate": 0.00019739897927714234,
      "loss": 2.0048885345458984,
      "step": 520
    },
    {
      "epoch": 0.29444444444444445,
      "grad_norm": 6.966058254241943,
      "learning_rate": 0.0001972620138620191,
      "loss": 1.8998580932617188,
      "step": 530
    },
    {
      "epoch": 0.3,
      "grad_norm": 23.86626434326172,
      "learning_rate": 0.00019712158419109597,
      "loss": 1.3267314910888672,
      "step": 540
    },
    {
      "epoch": 0.3055555555555556,
      "grad_norm": 83.5144271850586,
      "learning_rate": 0.0001969776952661642,
      "loss": 0.7327685356140137,
      "step": 550
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 35.50607681274414,
      "learning_rate": 0.00019683035221222618,
      "loss": 2.5140100479125977,
      "step": 560
    },
    {
      "epoch": 0.31666666666666665,
      "grad_norm": 3.2075796127319336,
      "learning_rate": 0.00019667956027731242,
      "loss": 2.388398361206055,
      "step": 570
    },
    {
      "epoch": 0.32222222222222224,
      "grad_norm": 12.061400413513184,
      "learning_rate": 0.00019652532483229514,
      "loss": 0.886569881439209,
      "step": 580
    },
    {
      "epoch": 0.3277777777777778,
      "grad_norm": 14.414532661437988,
      "learning_rate": 0.00019636765137069653,
      "loss": 1.2636883735656739,
      "step": 590
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 12.33552074432373,
      "learning_rate": 0.00019620654550849323,
      "loss": 2.1317699432373045,
      "step": 600
    },
    {
      "epoch": 0.3333333333333333,
      "eval_cls_acc": 0.885,
      "eval_cls_f1": 0.8718805704099821,
      "eval_loss": 1.1489671468734741,
      "eval_reg_mae": 0.6203689068555832,
      "eval_reg_r2": 0.7084115727056317,
      "eval_reg_rmse": 0.8919582686996045,
      "eval_runtime": 42.0797,
      "eval_samples_per_second": 19.012,
      "eval_steps_per_second": 2.376,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 5400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
